{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1-M7zLZ9JOs",
        "outputId": "8860f29c-3eb2-41ed-e20c-0aae6eb60ced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n",
            "67\n"
          ]
        }
      ],
      "source": [
        "tf_ifd_string = \"\"\"\n",
        "In information retrieval, tf–idf (also TF*IDF, TFIDF, TF–IDF, or Tf–idf), short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.\n",
        "\"\"\"\n",
        "#splits then counts words of above string\n",
        "words = tf_ifd_string.split(\" \")\n",
        "print(len(words))\n",
        "print(len(set(words)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "#finds most repeated word\n",
        "counter_words = dict(Counter(words))\n",
        "sorted_by_value = dict(sorted(counter_words.items(), key=lambda item: item[1], reverse=True))\n",
        "print(\"The most repeated word is \\\"\" + list(sorted_by_value.keys())[0] +\"\\\" with frequency of \"+ str(list(sorted_by_value.values())[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9l4A7n-BljG",
        "outputId": "26c2a3b9-7475-46f9-ef62-dbf947a2a2ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most repeated word is \"a\" with frequency of 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rDmFnomyGk9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP7XvT-Ltgwx",
        "outputId": "b6eaff42-fd07-4333-bbd7-bd3104f30e70"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_content = \"\"\n",
        "#open file\n",
        "with open('TFIDF.txt','r') as file:\n",
        "  file_content = file.read()\n",
        "words = file_content.split(\" \")\n",
        "#prints amount of words\n",
        "print(len(words))\n",
        "print(len(set(words)))\n",
        "#finds most repeated word\n",
        "from collections import Counter\n",
        "counter_words = dict(Counter(words))\n",
        "sorted_by_value = dict(sorted(counter_words.items(), key=lambda item: item[1], reverse=True))\n",
        "print(\"The most repeated word is \\\"\" + list(sorted_by_value.keys())[0] +\"\\\" with frequency of \"+ str(list(sorted_by_value.values())[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bisslZJtsKv",
        "outputId": "457ce6e2-a9c2-4559-dcf9-b6944c3464e7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n",
            "67\n",
            "The most repeated word is \"a\" with frequency of 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjlT6Gd_v_aq",
        "outputId": "accccf83-6e44-4a41-e736-31d28143f137"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "#finds most repeated word\n",
        "def print_most_frequent_word(words):\n",
        "  counter_words = dict(Counter(words))\n",
        "  sorted_by_value = dict(sorted(counter_words.items(), key=lambda item: item[1], reverse=True))\n",
        "  print(\"The most repeated word is \\\"\" + list(sorted_by_value.keys())[0] +\"\\\" with frequency of \"+ str(list(sorted_by_value.values())[0]))\n",
        "\n",
        "\n",
        "filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
        "print_most_frequent_word(words)\n",
        "print_most_frequent_word(filtered_words)\n",
        "  "
      ],
      "metadata": {
        "id": "2pwxfOSywV_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8cb72fd-8596-4a1f-813f-c76666110986"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most repeated word is \"a\" with frequency of 6\n",
            "The most repeated word is \"document\" with frequency of 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "JJKhFnqBviku"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0l6mMpg8toyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}