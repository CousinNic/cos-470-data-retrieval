{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive"
      ],
      "metadata": {
        "id": "NnkFH2iV3FqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#do not run if you workspace is located somewhere else\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"drive/MyDrive/Colab Notebooks\")\n",
        "os.listdir()\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGTlfhPKGuQi",
        "outputId": "e52d912e-79e8-4be2-9839-776426fcba0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " Assignment5.ipynb\t\t\t\t  Posts.xml\n",
            " BM25_qrel_5.txt\t\t\t\t  project_part1.ipynb\n",
            " BM25_result_5.txt\t\t\t\t  __pycache__\n",
            " BM25_result.txt\t\t\t\t  qrel.txt\n",
            " combMNZ.tsv\t\t\t\t\t 'Question 4.ipynb'\n",
            " Entities\t\t\t\t\t  RM3_result.txt\n",
            "'IR_Project2_Nicholas Drummey, Ryan Reed.ipynb'  'run to qrel converter.ipynb'\n",
            " LGD_qrel_5.txt\t\t\t\t\t  TF_IDF_qrel_5.txt\n",
            " LGD_result_5.txt\t\t\t\t  TF_IDF_result_5.txt\n",
            " LGD_result.txt\t\t\t\t\t  TF_IDF_result.txt\n",
            " pd_index\t\t\t\t\t  Untitled0.ipynb\n",
            " post_parser_record.py\t\t\t\t  word2vec.model\n",
            " Posts_Coffee.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1######################################################################"
      ],
      "metadata": {
        "id": "bqrNHwRF3Lem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from post_parser_record import PostParserRecord\n",
        "post_reader = PostParserRecord(\"Posts_Coffee.xml\")\n",
        "import nltk\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.test.utils import datapath\n",
        "from nltk.tokenize import word_tokenize\n",
        "from scipy.spatial import distance\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "import re"
      ],
      "metadata": {
        "id": "n33MF6fLqUhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0384da-6f4f-4856-9914-15860cbf87a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec"
      ],
      "metadata": {
        "id": "Wroj7YsIGqWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKsjaZRvEfxY",
        "outputId": "88880742-7511-4a1c-8c95-922be25b9724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexing Questions...\n",
            "Complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 1\t\t\tTitle: ['when', 'does', 'coffee', 'go', 'off']\n",
            "Score: 0.9999874234199524\tTitle: ['why', 'does', 'instant', 'coffee', 'foam', 'when', 'stirring', 'it']\n",
            "Score: 0.9999862313270569\tTitle: ['what', 'am', 'i', 'supposed', 'to', 'do', 'when', 'coffee', 'shop', 'leave', 'some', 'coffee', 'beans', 'in', 'my', 'latte']\n",
            "Score: 0.9999860525131226\tTitle: ['does', 'sweet', 'coffee', 'exist']\n",
            "Score: 0.9999857544898987\tTitle: ['does', 'coffee', 'taste', 'different', 'when', 'it', 'is', 'ground', 'at', 'home']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "array = []\n",
        "model = 0\n",
        "sentance_simularity = {}\n",
        "\n",
        "print(\"Indexing Questions...\")\n",
        "for question_id in post_reader.map_questions:\n",
        "  question = post_reader.map_questions[question_id]\n",
        "  title = question.title.lower().strip()\n",
        "  split_text = word_tokenize(re.sub(r'[^\\w\\s]', '', title))\n",
        "\n",
        "  array.append(split_text)\n",
        "print(\"Complete\")\n",
        "\n",
        "\n",
        "model = Word2Vec(sentences=array, window=5, min_count=1, workers=4)\n",
        "model.save(\"word2vec.model\")\n",
        "\n",
        "# train the word2vec model with the question titles\n",
        "model = Word2Vec.load(\"word2vec.model\")\n",
        "model.train(array, total_examples=len(array), epochs=10)\n",
        "\n",
        "\n",
        "# testing vector adding and dividing and such\n",
        "vector1 = model.wv['caffeine']\n",
        "vector2 = model.wv['tool']\n",
        "\n",
        "query_vector = (model.wv['when']+model.wv['does']+model.wv['coffee']+model.wv['go']+model.wv['off'])\n",
        "query_vector = query_vector/5\n",
        " \n",
        "for sentence in array:\n",
        "  sentence_vector = 0\n",
        "  for word in sentence:\n",
        "    sentence_vector += model.wv[word]\n",
        "  sentence_vector = sentence_vector/len(sentence)\n",
        "  sentance_simularity[str(sentence)] = 1-distance.cosine(query_vector, sentence_vector)\n",
        "\n",
        "\n",
        "result = sorted(sentance_simularity.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "i = 0\n",
        "for items in result:\n",
        "  #makes sure only 5 of each are printed\n",
        "  if i <= 4:\n",
        "    if items[1] == 1:\n",
        "      print(\"Score: \"+str(items[1])+\"\\t\\t\\tTitle: \"+str(items[0]))\n",
        "    else:\n",
        "      print(\"Score: \"+str(items[1])+\"\\tTitle: \"+str(items[0]))\n",
        "    i += 1\n",
        "  else:\n",
        "    break\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2######################################################################"
      ],
      "metadata": {
        "id": "VZPhq91IKD8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-terrier\n",
        "!pip install --upgrade git+https://github.com/terrier-org/pyterrier.git\n",
        "import pyterrier as pt\n",
        "pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])\n",
        "\n",
        "import pandas as pd\n",
        "!rm -rf ./pd_index\n",
        "pd_indexer = pt.DFIndexer(\"./pd_index\")\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "1ycHXW5XlOMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docno_list = []\n",
        "url_list = []\n",
        "text_list = []\n",
        "#indexed questions\n",
        "print(\"Indexing Questions...\")\n",
        "for question_id in post_reader.map_questions:\n",
        "  question = post_reader.map_questions[question_id]\n",
        "  text = question.body.lower().strip()\n",
        "  docno_list.append(str(question_id))\n",
        "  url_list.append(\"url\"+str(question_id))\n",
        "  text_list.append(text)\n",
        "print(\"Complete\")\n",
        "\n",
        "print(\"Finalizing...\")\n",
        "\n",
        "#adds all collected data to a DataFrame from above\n",
        "df = pd.DataFrame({'docno':docno_list, 'url':url_list, 'text':text_list})\n",
        "indexref = pd_indexer.index(df[\"text\"], df)\n",
        "index = pt.IndexFactory.of(indexref)\n",
        "\n",
        "#prints info on colected documents, (should have 185140 documents)\n",
        "print(index.getCollectionStatistics().toString())"
      ],
      "metadata": {
        "id": "Ue9noykp5yIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312147b4-4113-4a20-8948-da4a2b442f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexing Questions...\n",
            "Complete\n",
            "Finalizing...\n",
            "Number of documents: 1370\n",
            "Number of terms: 5225\n",
            "Number of postings: 43420\n",
            "Number of fields: 0\n",
            "Number of tokens: 57129\n",
            "Field names: []\n",
            "Positions:   false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "def searchTopK(k):\n",
        "  querys = [\"1\",\"how to make espresso\"], [\"2\", \"moka pot\"], [\"3\", \"coffee caffeine\"]\n",
        "  #add querys to dataframe\n",
        "  queries = pd.DataFrame(querys,columns=['qid','query'])\n",
        "  #find top 1000 results with pyterrier Batch Retrieve, from the created index\n",
        "  result = pt.BatchRetrieve(indexref, num_results =k, wmodel=\"TF_IDF\").transform(queries)\n",
        "  #write results to file and print\n",
        "  #print(result)\n",
        "  last_query = ''\n",
        "\n",
        "  tag_frequency = {}\n",
        "  passes_num = 0\n",
        "  for i in result.docno:\n",
        "    question = post_reader.map_questions[int(i)]\n",
        "    #print benining\n",
        "    if last_query is not result.qid[passes_num]:\n",
        "      print(\"Query: \"+str(querys[int(result.qid[passes_num])-1][1]))\n",
        "      tag_frequency = {}\n",
        "    last_query = copy.copy(result.qid[passes_num])\n",
        "\n",
        "  \n",
        "    passes_num+=1\n",
        "    #print(question.tags)\n",
        "    for tag in question.tags:\n",
        "      if tag not in tag_frequency:\n",
        "        tag_frequency[tag] = 1\n",
        "      else:\n",
        "        tag_frequency[tag] += 1\n",
        "      \n",
        "    #print ending\n",
        "    if (int(passes_num/k+1)) is not int(result.qid[passes_num-1]):\n",
        "      sorted_tags = sorted(tag_frequency.items(), key=lambda x: x[1], reverse=True)\n",
        "      print(\"most common tag is: [\"+str(sorted_tags[0][0])+\"] with frequency of: \"+str(sorted_tags[0][1]))\n",
        "\n",
        "print(\"Tag of top 1 result:\")\n",
        "searchTopK(1)\n",
        "print(\"\\nTag of top 5 result:\")\n",
        "searchTopK(5)\n",
        "print(\"\\nTag of top 10 result:\")\n",
        "searchTopK(10)\n",
        "print(\"\\nTag of top 20 result:\")\n",
        "searchTopK(20)"
      ],
      "metadata": {
        "id": "pL2IhNTBh5kI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80043154-9fe9-4756-fa5d-f0821ac85d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag of top 1 result:\n",
            "Query: how to make espresso\n",
            "most common tag is: [espresso] with frequency of: 1\n",
            "Query: moka pot\n",
            "most common tag is: [equipment] with frequency of: 1\n",
            "Query: coffee caffeine\n",
            "most common tag is: [decaffeinated] with frequency of: 1\n",
            "\n",
            "Tag of top 5 result:\n",
            "Query: how to make espresso\n",
            "most common tag is: [espresso] with frequency of: 5\n",
            "Query: moka pot\n",
            "most common tag is: [moka] with frequency of: 5\n",
            "Query: coffee caffeine\n",
            "most common tag is: [caffeine] with frequency of: 4\n",
            "\n",
            "Tag of top 10 result:\n",
            "Query: how to make espresso\n",
            "most common tag is: [espresso] with frequency of: 8\n",
            "Query: moka pot\n",
            "most common tag is: [moka] with frequency of: 10\n",
            "Query: coffee caffeine\n",
            "most common tag is: [caffeine] with frequency of: 8\n",
            "\n",
            "Tag of top 20 result:\n",
            "Query: how to make espresso\n",
            "most common tag is: [espresso] with frequency of: 17\n",
            "Query: moka pot\n",
            "most common tag is: [moka] with frequency of: 19\n",
            "Query: coffee caffeine\n",
            "most common tag is: [caffeine] with frequency of: 18\n"
          ]
        }
      ]
    }
  ]
}